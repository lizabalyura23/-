{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1eh2H8oeqGe5nOLk0MvAN21ZCgOHguULm",
      "authorship_tag": "ABX9TyOFV+6K8ZOUraBdnpJ+murM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lizabalyura23/-/blob/main/model%2Bbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3qCBR84xEv_",
        "outputId": "93f9b206-6d45-4a04-a525-c1a6c36b91af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3135 files belonging to 36 classes.\n",
            "Found 359 files belonging to 36 classes.\n",
            "Found 351 files belonging to 36 classes.\n",
            "Found 3135 images belonging to 36 classes.\n",
            "Found 351 images belonging to 36 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n",
            "Found 359 images belonging to 36 classes.\n",
            "Epoch 1/20\n",
            " 6/98 [>.............................] - ETA: 13:26 - loss: 3.6028 - accuracy: 0.0625"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - ETA: 0s - loss: 1.8582 - accuracy: 0.5072 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r98/98 [==============================] - 1109s 11s/step - loss: 1.8582 - accuracy: 0.5072 - val_loss: 0.6189 - val_accuracy: 0.8405\n",
            "Epoch 2/20\n",
            "98/98 [==============================] - 388s 4s/step - loss: 0.8034 - accuracy: 0.7528 - val_loss: 0.4715 - val_accuracy: 0.8291\n",
            "Epoch 3/20\n",
            "98/98 [==============================] - 335s 3s/step - loss: 0.5902 - accuracy: 0.8045 - val_loss: 0.3808 - val_accuracy: 0.8661\n",
            "Epoch 4/20\n",
            "98/98 [==============================] - 352s 4s/step - loss: 0.4707 - accuracy: 0.8376 - val_loss: 0.3312 - val_accuracy: 0.8860\n",
            "Epoch 5/20\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.4439 - accuracy: 0.8456Epoch 6/20\n",
            "98/98 [==============================] - 350s 4s/step - loss: 0.3512 - accuracy: 0.8759 - val_loss: 0.2587 - val_accuracy: 0.9117\n",
            "Epoch 7/20\n",
            "98/98 [==============================] - 339s 3s/step - loss: 0.3283 - accuracy: 0.8788 - val_loss: 0.2893 - val_accuracy: 0.9117\n",
            "Epoch 8/20\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2825 - accuracy: 0.8976Restoring model weights from the end of the best epoch: 6.\n",
            "98/98 [==============================] - 331s 3s/step - loss: 0.2825 - accuracy: 0.8976 - val_loss: 0.2694 - val_accuracy: 0.9288\n",
            "Epoch 8: early stopping\n",
            "12/12 [==============================] - 96s 8s/step - loss: 0.2488 - accuracy: 0.9109\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import Callback, ModelCheckpoint,EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.applications import mobilenet_v2\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Устанавливаем пути к директориям для обучающего, валидационного и тестового наборов данных\n",
        "train_dir = pathlib.Path(\"/content/drive/MyDrive/datasets/train\")\n",
        "test_dir = pathlib.Path(\"/content/drive/MyDrive/datasets/test\")\n",
        "val_dir = pathlib.Path(\"/content/drive/MyDrive/datasets/validation\")\n",
        "\n",
        "\n",
        "# Устанавливаем размеры изображений\n",
        "img_height = 224\n",
        "img_weigth = 224\n",
        "\n",
        "# Загружаем наборы данных с помощью image_dataset_from_directory\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(train_dir)\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(test_dir)\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(val_dir)\n",
        "# Получаем имена классов и количество классов\n",
        "class_names = dict(zip(train_ds.class_names, range(len(train_ds.class_names))))\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# Создаем генератор изображений для аугментации данных и их предобработки\n",
        "train_generator = ImageDataGenerator(\n",
        "preprocessing_function = mobilenet_v2.preprocess_input,\n",
        "rotation_range = 32,\n",
        "zoom_range = 0.2,\n",
        "width_shift_range = 0.2,\n",
        "height_shift_range = 0.2,\n",
        "shear_range = 0.2,\n",
        "horizontal_flip = True,\n",
        "fill_mode = \"nearest\")\n",
        "\n",
        "# Загружаем и предобрабатываем обучающие данные\n",
        "train = train_generator.flow_from_directory(train_dir,\n",
        "target_size = (img_height,img_weigth),\n",
        "# изображение имеет 3 цветовых канала\n",
        "color_mode = \"rgb\",\n",
        "# создаем бинарные признаки меток класса\n",
        "class_mode = \"categorical\",\n",
        "batch_size = 32,\n",
        "shuffle = True,\n",
        "seed = 123)\n",
        "\n",
        "# Загружаем и предобрабатываем валидационные данные\n",
        "validation = train_generator.flow_from_directory(val_dir,\n",
        "target_size = (img_height,img_weigth),\n",
        "# изображение имеет 3 цветовых канала\n",
        "color_mode = \"rgb\",\n",
        "# создаем бинарные признаки меток класса\n",
        "class_mode = \"categorical\",\n",
        "batch_size = 32,\n",
        "shuffle = True,\n",
        "seed = 123)\n",
        "\n",
        "# Загружаем модель MobileNetV2 с предварительно обученными весами ImageNet\n",
        "mobilenet_ = MobileNetV2(\n",
        "input_shape = (img_height,img_weigth,3),\n",
        "include_top = False,\n",
        "weights = 'imagenet',\n",
        "pooling = 'avg')\n",
        "\n",
        "# Замораживаем слои базовой модели\n",
        "mobilenet_.trainable = False\n",
        "\n",
        "\n",
        "# Создаем модель, добавив настраиваемые слои поверх базовой модели\n",
        "inputs = mobilenet_.input\n",
        "x = Dense(128, activation = 'relu')(mobilenet_.output)\n",
        "x = Dense(128, activation = 'relu')(x)\n",
        "outputs = Dense(num_classes , activation = 'softmax')(x)\n",
        "\n",
        "# Определяем полную модель\n",
        "mobilenet = Model(inputs = inputs, outputs = outputs)\n",
        "\n",
        "# Устанавливаем раннюю остановку для предотвращения переобучения и сохранение лучших весов модели\n",
        "early_stopping = EarlyStopping(\n",
        "\tmonitor='val_loss',\n",
        "\tmode='min',\n",
        "\tpatience = 2,\n",
        "\tverbose=1,\n",
        "\trestore_best_weights=True,\n",
        ")\n",
        "checkpoint =ModelCheckpoint('/content/drive/MyDrive/fruit224mobile.h5',\n",
        "                        \tmonitor = 'val_loss',\n",
        "                        \tmode = 'min',\n",
        "                       \tsave_best_only = True)\n",
        "\n",
        "# Компилируем модель с оптимизатором Adam и категориальной кросс-энтропией в качестве функции потерь\n",
        "callbacks = [early_stopping, checkpoint]\n",
        "\n",
        "mobilenet.compile(optimizer=Adam(learning_rate=0.001), loss ='categorical_crossentropy',metrics = ['accuracy'])\n",
        "\n",
        "# Загружаем и предобрабатываем тестовые данные\n",
        "test = train_generator.flow_from_directory(test_dir,\n",
        "target_size = (224,224),\n",
        "color_mode = \"rgb\",\n",
        "class_mode = \"categorical\",\n",
        "batch_size = 32,\n",
        "shuffle = False)\n",
        "\n",
        "# Обучаем модель на обучающих данных и проводим валидацию на валидационных данных\n",
        "history = mobilenet.fit(\n",
        "train, validation_data = validation,\n",
        "epochs = 20,\n",
        "callbacks = callbacks)\n",
        "\n",
        "# Оцениваем модель на тестовых данных\n",
        "(eval_loss, eval_accuracy) = mobilenet.evaluate(test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Загрузка модели\n",
        "model_path = '/content/drive/MyDrive/fruit224mobile.h5'\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# Маппинг классов\n",
        "class_names = {\n",
        "    0: 'Яблоко',\n",
        "    1: 'Банан',\n",
        "    2: 'Свекла',\n",
        "    3: 'Болгарский перец',\n",
        "    4: 'Капуста',\n",
        "    5: 'Стручковый перец',\n",
        "    6: 'Морковь',\n",
        "    7: 'Цветная капуста',\n",
        "    8: 'Перец чили',\n",
        "    9: 'Кукуруза',\n",
        "    10: 'Огурец',\n",
        "    11: 'Баклажан',\n",
        "    12: 'Чеснок',\n",
        "    13: 'Имбирь',\n",
        "    14: 'Виноград',\n",
        "    15: 'Халапеньо',\n",
        "    16: 'Киви',\n",
        "    17: 'Лимон',\n",
        "    18: 'Латук',\n",
        "    19: 'Манго',\n",
        "    20: 'Лук',\n",
        "    21: 'Апельсин',\n",
        "    22: 'Паприка',\n",
        "    23: 'Груша',\n",
        "    24: 'Горох',\n",
        "    25: 'Ананас',\n",
        "    26: 'Гранат',\n",
        "    27: 'Картофель',\n",
        "    28: 'Редька',\n",
        "    29: 'Соевые бобы',\n",
        "    30: 'Шпинат',\n",
        "    31: 'Сладкая кукуруза',\n",
        "    32: 'Батат',\n",
        "    33: 'Помидор',\n",
        "    34: 'Репа',\n",
        "    35: 'Арбуз'\n",
        "}\n",
        "\n",
        "# Функция для предсказания класса изображения\n",
        "def predict_image(image_path):\n",
        "    # Загрузка и предобработка изображения\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = tf.keras.applications.mobilenet_v2.preprocess_input(img)\n",
        "\n",
        "    # Предсказание класса\n",
        "    predictions = model.predict(img)\n",
        "    predicted_class = np.argmax(predictions[0])\n",
        "    predicted_label = class_names[predicted_class]\n",
        "\n",
        "    return predicted_label\n",
        "\n",
        "# Тестирование функции предсказания\n",
        "image_path = '/content/Image_3.jpg'  # Замените на путь к тестовому изображению\n",
        "predicted_label = predict_image(image_path)\n",
        "print(f\"Предсказанный класс: {predicted_label}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdiS1lHOvscJ",
        "outputId": "f773dff9-082d-4c0a-b8af-48db3d82d7cc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 843ms/step\n",
            "Предсказанный класс: Банан\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aiogram"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1cRPI_sTCBT",
        "outputId": "e666566d-c7b9-42a6-fb32-5dd04dc3d15b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting aiogram\n",
            "  Downloading aiogram-3.6.0-py3-none-any.whl (540 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/540.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/540.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m532.5/540.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.1/540.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles~=23.2.1 (from aiogram)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: aiohttp~=3.9.0 in /usr/local/lib/python3.10/dist-packages (from aiogram) (3.9.5)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from aiogram) (2024.2.2)\n",
            "Collecting magic-filter<1.1,>=1.0.12 (from aiogram)\n",
            "  Downloading magic_filter-1.0.12-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pydantic<2.8,>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from aiogram) (2.7.1)\n",
            "Requirement already satisfied: typing-extensions<=5.0,>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from aiogram) (4.11.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.9.0->aiogram) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.9.0->aiogram) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.9.0->aiogram) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.9.0->aiogram) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.9.0->aiogram) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.9.0->aiogram) (4.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.8,>=2.4.1->aiogram) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.8,>=2.4.1->aiogram) (2.18.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp~=3.9.0->aiogram) (3.7)\n",
            "Installing collected packages: magic-filter, aiofiles, aiogram\n",
            "Successfully installed aiofiles-23.2.1 aiogram-3.6.0 magic-filter-1.0.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ПОБЕДА!!!!!!\n",
        "import logging\n",
        "import os\n",
        "from aiogram import Bot, Dispatcher, types\n",
        "from aiogram.filters.command import Command\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from aiogram import F\n",
        "import asyncio\n",
        "import cv2\n",
        "\n",
        "# Настройка логирования\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# Создание экземпляра бота с токеном\n",
        "bot = Bot(token='6959067623:AAFphw5BAC0dqooMfve_TCFnwXlz-m8eEr4')\n",
        "dp = Dispatcher()\n",
        "\n",
        "# Функция для предсказания класса\n",
        "def predictions(img_path):\n",
        "    classifier = tf.keras.models.load_model(\"/content/drive/MyDrive/fruit224mobile.h5\")\n",
        "    class_labels = {\n",
        "        0: 'Яблоко',\n",
        "        1: 'Банан',\n",
        "        2: 'Свекла',\n",
        "        3: 'Болгарский перец',\n",
        "        4: 'Капуста',\n",
        "        5: 'Стручковый перец',\n",
        "        6: 'Морковь',\n",
        "        7: 'Цветная капуста',\n",
        "        8: 'Перец чили',\n",
        "        9: 'Кукуруза',\n",
        "        10: 'Огурец',\n",
        "        11: 'Баклажан',\n",
        "        12: 'Чеснок',\n",
        "        13: 'Имбирь',\n",
        "        14: 'Виноград',\n",
        "        15: 'Халапеньо',\n",
        "        16: 'Киви',\n",
        "        17: 'Лимон',\n",
        "        18: 'Латук',\n",
        "        19: 'Манго',\n",
        "        20: 'Лук',\n",
        "        21: 'Апельсин',\n",
        "        22: 'Паприка',\n",
        "        23: 'Груша',\n",
        "        24: 'Горох',\n",
        "        25: 'Ананас',\n",
        "        26: 'Гранат',\n",
        "        27: 'Картофель',\n",
        "        28: 'Редька',\n",
        "        29: 'Соевые бобы',\n",
        "        30: 'Шпинат',\n",
        "        31: 'Сладкая кукуруза',\n",
        "        32: 'Батат',\n",
        "        33: 'Помидор',\n",
        "        34: 'Репа',\n",
        "        35: 'Арбуз'\n",
        "    }\n",
        "    # Загрузка изображения\n",
        "    img = cv2.imread(img_path)\n",
        "    # Изменение размера изображения\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    # Конвертация изображения из BGR в RGB\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    # Добавление измерения для batch\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    # Предобработка изображения\n",
        "    img = tf.keras.applications.mobilenet_v2.preprocess_input(img)\n",
        "\n",
        "\n",
        "    # Предсказание класса\n",
        "    predictions = classifier.predict(img)\n",
        "    predicted_class = np.argmax(predictions[0])\n",
        "    predicted_label = class_labels[predicted_class]\n",
        "\n",
        "    return predicted_label\n",
        "\n",
        "# Функция для загрузки изображения и преобразования его в массив\n",
        "def get_img_array(img_path, size):\n",
        "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=size)\n",
        "    array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "# Обработчик команды /start\n",
        "@dp.message(Command(\"start\"))\n",
        "async def start(message: types.Message):\n",
        "    await message.reply('Привет! Я бот, распознающий овощи и фрукты')\n",
        "\n",
        "# Обработчик команды /help\n",
        "@dp.message(Command(\"help\"))\n",
        "async def help(message: types.Message):\n",
        "    await message.reply('Просто отправьте мне изображение, которое содержит овощ или фрукт')\n",
        "\n",
        "\n",
        "# Обработка полученных фотографий\n",
        "@dp.message(F.photo)\n",
        "async def download_photo(message: types.Message, bot: Bot):\n",
        "    # Сохранение изображения во временный файл\n",
        "    img_path = f\"tmp/{message.photo[-1].file_id}.jpg\"\n",
        "    await bot.download(\n",
        "        message.photo[-1],\n",
        "        destination=img_path\n",
        "    )\n",
        "    print(f\"Downloaded photo path: {img_path}\")\n",
        "    # Предсказание класса объекта на изображении\n",
        "    pred = predictions(img_path)\n",
        "    await message.answer(f\"Я думаю, что это {pred} 😊\")\n",
        "\n",
        "\n",
        "#запуск бота\n",
        "async def main():\n",
        "    await dp.start_polling(bot)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "6L3NNVXMlcac",
        "outputId": "26d56cd6-683c-47cc-bca3-ea041696834b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "asyncio.run() cannot be called from a running event loop",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-e4eb6b8ce2e0>\u001b[0m in \u001b[0;36m<cell line: 105>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/runners.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \"\"\"\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m     34\u001b[0m             \"asyncio.run() cannot be called from a running event loop\")\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#победа\n",
        "await main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhSdFyTamZl4",
        "outputId": "9d881b0b-a743-45be-befa-3306a57972af"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded photo path: tmp/AgACAgIAAxkBAAMxZk9C6AM90t05EezpZDEzY8J_8qwAAlHkMRtz7IBKzNWOM34TT6oBAAMCAAN5AAM1BA.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7e9d48a29630> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 856ms/step\n",
            "Downloaded photo path: tmp/AgACAgIAAxkBAAM0Zk9DGidmSW6cLkb73c5UfT6PJTQAAoLVMRt-WnFK2WsOHOYpktwBAAMCAAN4AAM1BA.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Downloaded photo path: tmp/AgACAgIAAxkBAAM2Zk9DIJR6Ff4qupArI0MCx5IjZo4AAlPkMRtz7IBKpFeE4BF5_4IBAAMCAAN5AAM1BA.jpg\n",
            "1/1 [==============================] - 1s 858ms/step\n",
            "Downloaded photo path: tmp/AgACAgIAAxkBAAM4Zk9D0c882A63iYtFXnWukGINWrIAAn7dMRsSOXhKyh8myYERx9kBAAMCAAN5AAM1BA.jpg\n",
            "1/1 [==============================] - 1s 876ms/step\n",
            "Downloaded photo path: tmp/AgACAgIAAxkBAAM6Zk9D8Vr88UaPFYZz16WBAvaGAU4AAn_dMRsSOXhKMFfPc_-A9BcBAAMCAAN5AAM1BA.jpg\n",
            "1/1 [==============================] - 1s 860ms/step\n",
            "Downloaded photo path: tmp/AgACAgIAAxkBAAM8Zk9EDMkeBmrtvPTm7EPsPFT4bAIAAoHdMRsSOXhK9wXG-t6ferABAAMCAAN5AAM1BA.jpg\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Downloaded photo path: tmp/AgACAgIAAxkBAAM-Zk9ERKhiK0lfE6t1iayEtVeE9pIAAoLdMRsSOXhKn_MilyZu3eQBAAMCAAN5AAM1BA.jpg\n",
            "1/1 [==============================] - 1s 817ms/step\n",
            "Downloaded photo path: tmp/AgACAgIAAxkBAANAZk9EbuU1HU5cN8rSlW_HfHyq9NEAAojdMRsSOXhKpGIKWPvXzEABAAMCAAN5AAM1BA.jpg\n",
            "1/1 [==============================] - 1s 831ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:aiogram.dispatcher:Received SIGINT signal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MTLd4UO72kGJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}